{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "069b8c77",
      "metadata": {
        "id": "069b8c77"
      },
      "source": [
        "# Modelado de lenguaje a nivel de carÃ¡cter en TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19f465a4",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-05-10T15:09:40.469396Z",
          "start_time": "2023-05-10T15:09:32.091784Z"
        },
        "id": "19f465a4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ce4b0ae",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-05-10T15:09:41.671050Z",
          "start_time": "2023-05-10T15:09:41.614195Z"
        },
        "id": "3ce4b0ae"
      },
      "outputs": [],
      "source": [
        "## Reading and processing text\n",
        "\n",
        "with open('/content/sample_data/1268-0.txt', 'r', encoding = 'utf8') as fp:\n",
        "    text = fp.read()\n",
        "    \n",
        "start_indx = text.find('THE MYSTERIOUS ISLAND')\n",
        "end_indx = text.find('End of the Project Gutenberg')\n",
        "text = text[start_indx:end_indx]\n",
        "char_set = set(text)\n",
        "print('Total Length:', len(text))    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f41a369",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-05-10T15:09:44.644736Z",
          "start_time": "2023-05-10T15:09:44.632766Z"
        },
        "id": "5f41a369"
      },
      "outputs": [],
      "source": [
        "print('Unique Characters:', len(char_set))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "faa44b38",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-05-10T15:12:44.570162Z",
          "start_time": "2023-05-10T15:12:44.312300Z"
        },
        "scrolled": true,
        "id": "faa44b38"
      },
      "outputs": [],
      "source": [
        "## Building the dictionary to map \n",
        "## characters to integers, and reverse mapping\n",
        "\n",
        "chars_sorted = sorted(char_set)\n",
        "\n",
        "char2int = {ch:i for i,ch in enumerate(chars_sorted)}\n",
        "char_array = np.array(chars_sorted)\n",
        "\n",
        "text_encoded = np.array(\n",
        "    [char2int[ch] for ch in text],\n",
        "    dtype=np.int32)\n",
        "\n",
        "print('Text encoded shape:', text_encoded.shape)\n",
        "print(text[:15], '== Encoding ==>', text_encoded[:15])\n",
        "print(text_encoded[15:21], '== Reverse ==>',\n",
        "     ''.join(char_array[text_encoded[15:21]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5ac35a0",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-05-10T15:12:46.809308Z",
          "start_time": "2023-05-10T15:12:46.565257Z"
        },
        "id": "a5ac35a0"
      },
      "outputs": [],
      "source": [
        "ds_text_encoded = tf.data.Dataset.from_tensor_slices(\n",
        "    text_encoded)\n",
        "\n",
        "for ex in ds_text_encoded.take(5):\n",
        "    print('{} -> {}'.format(ex.numpy(), char_array[ex.numpy()]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21cf8eec",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-05-10T15:12:48.727828Z",
          "start_time": "2023-05-10T15:12:48.562735Z"
        },
        "id": "21cf8eec"
      },
      "outputs": [],
      "source": [
        "seq_length = 60\n",
        "chunk_size = seq_length + 1\n",
        "ds_chunks = ds_text_encoded.batch(chunk_size, drop_remainder=True)\n",
        "\n",
        "## define the function for splitting x & y\n",
        "def split_input_target(chunk):\n",
        "    \n",
        "    input_seq = chunk[:-1]\n",
        "    target_seq = chunk[1:]\n",
        "    return input_seq, target_seq\n",
        "\n",
        "ds_sequences = ds_chunks.map(split_input_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00a5d5d0",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-05-10T15:12:50.368898Z",
          "start_time": "2023-05-10T15:12:50.280986Z"
        },
        "id": "00a5d5d0"
      },
      "outputs": [],
      "source": [
        "## Example of how ds_sequences is made up\n",
        "\n",
        "for example in ds_sequences.take(2):\n",
        "    print(' Input (x): ',\n",
        "    repr(''.join(char_array[example[0].numpy()])))\n",
        "    print('Target (y): ',\n",
        "    repr(''.join(char_array[example[1].numpy()])))\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4dcce6dd",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-05-10T15:12:52.334308Z",
          "start_time": "2023-05-10T15:12:52.306386Z"
        },
        "id": "4dcce6dd"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 10000\n",
        "ds = ds_sequences.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6841b3b1",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-05-10T15:12:53.882438Z",
          "start_time": "2023-05-10T15:12:53.871466Z"
        },
        "id": "6841b3b1"
      },
      "outputs": [],
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units):\n",
        "    model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
        "    tf.keras.layers.LSTM(\n",
        "    rnn_units,\n",
        "    return_sequences=True),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(vocab_size),\n",
        "    ])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "902bfa37",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-05-10T15:12:55.572359Z",
          "start_time": "2023-05-10T15:12:55.560863Z"
        },
        "id": "902bfa37"
      },
      "outputs": [],
      "source": [
        "## Setting the training parameters\n",
        "charset_size = len(char_array)\n",
        "embedding_dim = 256\n",
        "rnn_units = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5aaa51a1",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-05-10T15:12:58.097199Z",
          "start_time": "2023-05-10T15:12:57.027833Z"
        },
        "id": "5aaa51a1"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(1)\n",
        "model = build_model(\n",
        "    vocab_size=charset_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0a8de1d",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2023-05-10T15:13:00.345Z"
        },
        "id": "b0a8de1d"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True\n",
        "    ))\n",
        "\n",
        "model.fit(ds, epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f876d31",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2023-05-10T15:13:01.894Z"
        },
        "id": "2f876d31"
      },
      "outputs": [],
      "source": [
        "## Ejemplos\n",
        "\n",
        "tf.random.set_seed(1)\n",
        "logits = [[1.0, 1.0, 1.0]]\n",
        "print('Probabilities:', tf.math.softmax(logits).numpy()[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75d698a6",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-05-10T03:02:38.839885Z",
          "start_time": "2023-05-10T03:02:38.808869Z"
        },
        "id": "75d698a6"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(1)\n",
        "samples = tf.random.categorical(\n",
        "logits=logits, num_samples=10)\n",
        "\n",
        "tf.print(samples.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a52f0a86",
      "metadata": {
        "id": "a52f0a86"
      },
      "outputs": [],
      "source": [
        "def sample(model, starting_str,\n",
        "    len_generated_text=500,\n",
        "    max_input_length=60,\n",
        "    scale_factor=2.0):\n",
        "  \n",
        "    encoded_input = [char2int[s] for s in starting_str]\n",
        "    encoded_input = tf.reshape(encoded_input, (1, -1))\n",
        "\n",
        "    generated_str = starting_str\n",
        "\n",
        "    model.reset_states()\n",
        "    for i in range(len_generated_text):\n",
        "        logits = model(encoded_input)\n",
        "        logits = tf.squeeze(logits, 0)\n",
        "\n",
        "        scaled_logits = logits * scale_factor\n",
        "        new_char_indx = tf.random.categorical(\n",
        "                 scaled_logits, num_samples=1)\n",
        "\n",
        "        new_char_indx = tf.squeeze(new_char_indx)[-1].numpy()\n",
        "\n",
        "        generated_str += str(char_array[new_char_indx])\n",
        "\n",
        "        new_char_indx = tf.expand_dims([new_char_indx], 0)\n",
        "        encoded_input = tf.concat(\n",
        "             [encoded_input, new_char_indx],\n",
        "                            axis=1)\n",
        "        encoded_input = encoded_input[:, -max_input_length:]\n",
        "\n",
        "\n",
        "    return generated_str"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(1)\n",
        "print(sample(model, starting_str='The island'))"
      ],
      "metadata": {
        "id": "0bbA6PNtj9QZ"
      },
      "id": "0bbA6PNtj9QZ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}